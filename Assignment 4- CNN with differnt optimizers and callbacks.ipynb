{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#Assignment 4 :CNN Image Classification model with augmented data and using various optimisers, callbacks and learning rates**\n",
    "\n",
    "\n",
    "\n",
    "Using following optimisers:\n",
    "\n",
    "\n",
    "\n",
    "1) SGD + Momentum\n",
    "\n",
    "2) Nesterov Accelerated Gradient Descent\n",
    "\n",
    "3) RMSprop\n",
    "\n",
    "4) Adam\n",
    "\n",
    "5) Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising CNN\n",
    "def get_model():\n",
    "    Model=Sequential()\n",
    "#1st layer\n",
    "    Model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(64,64,3),activation='relu'))\n",
    "\n",
    "#2nd layer\n",
    "    Model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "    Model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    Model.add(Dropout(0.25))\n",
    "#Flattening layer\n",
    "    Model.add(Flatten())\n",
    "#Full connection layer\n",
    "    Model.add(Dense(units=128,activation='relu'))\n",
    "    Model.add(Dense(units=3,activation='softmax'))\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**---As we have already augmented our data in previous assignment so here I assign that augmented data to my train generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 899 images belonging to 3 classes.\n",
      "Found 75 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen=ImageDataGenerator(rescale=1./255)\n",
    "training=train_gen.flow_from_directory('C:/Users/Arjun Rao/Desktop/Training',\n",
    "                                       target_size=(64,64),batch_size=20,class_mode='categorical')\n",
    "\n",
    "test_gen=ImageDataGenerator(rescale=1./255)\n",
    "test=test_gen.flow_from_directory('C:/Users/Arjun Rao/Desktop/Test',\n",
    "                                  target_size=(64,64),batch_size=5,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing Callbacks - [Early stopping, Model Checkpoint, Learning Rate Scheduler]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStop=EarlyStopping(patience=3,monitor ='val_loss',restore_best_weights = True,verbose=1)\n",
    "\n",
    "ModelCheck=ModelCheckpoint(filepath=r\"D:/amazon_classifier/amazon_cnn_1.h5\", monitor='val_loss',\n",
    "                           mode='min',save_best_only=True,verbose=1)\n",
    "\n",
    "ReduceLR=ReduceLROnPlateau(patience=3,monitor ='val_loss',factor=0.2,min_delta=0.0001, verbose=1)\n",
    "\n",
    "my_callbacks=[EarlyStop,ModelCheck,ReduceLR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------Different Optimizing techniques-----------------**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**SGD (with momentum and without nesterov)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 131s 1s/step - loss: 0.9825 - accuracy: 0.5233 - val_loss: 0.9821 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.54879\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 128s 1s/step - loss: 0.7672 - accuracy: 0.6558 - val_loss: 0.5066 - val_accuracy: 0.7240\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54879 to 0.50661, saving model to D:/amazon_classifier/amazon_cnn_1.h5\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 129s 1s/step - loss: 0.6367 - accuracy: 0.7161 - val_loss: 0.4341 - val_accuracy: 0.7160\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.50661 to 0.43415, saving model to D:/amazon_classifier/amazon_cnn_1.h5\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.5346 - accuracy: 0.7708 - val_loss: 0.4283 - val_accuracy: 0.7240\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.43415 to 0.42826, saving model to D:/amazon_classifier/amazon_cnn_1.h5\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.4318 - accuracy: 0.8278 - val_loss: 0.3103 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42826 to 0.31031, saving model to D:/amazon_classifier/amazon_cnn_1.h5\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.3521 - accuracy: 0.8684 - val_loss: 0.4150 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31031\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2751 - accuracy: 0.9039 - val_loss: 0.5389 - val_accuracy: 0.8160\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31031\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2048 - accuracy: 0.9334 - val_loss: 1.0089 - val_accuracy: 0.8200\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31031\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "opt=keras.optimizers.SGD(learning_rate=0.01, momentum=0.1, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model.fit_generator(training,steps_per_epoch=100,epochs=20,validation_data=test,validation_steps=50,\n",
    "                    callbacks=my_callbacks,verbose=1)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD (with momentum and with nesterov)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCheck=ModelCheckpoint(filepath=r\"D:/amazon_classifier/amazon_cnn_SGD_Nestrov.h5\",\n",
    "                           monitor='val_loss',mode='min',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.3148 - accuracy: 0.8814 - val_loss: 0.0679 - val_accuracy: 0.8080\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06792, saving model to D:/amazon_classifier/amazon_cnn_SGD_Nestrov.h5\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.2945 - accuracy: 0.8944 - val_loss: 0.4631 - val_accuracy: 0.8160\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06792\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.2705 - accuracy: 0.9079 - val_loss: 0.3175 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06792\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.2532 - accuracy: 0.9109 - val_loss: 0.0616 - val_accuracy: 0.8640\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06792 to 0.06165, saving model to D:/amazon_classifier/amazon_cnn_SGD_Nestrov.h5\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2374 - accuracy: 0.9234 - val_loss: 0.4031 - val_accuracy: 0.8760\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06165\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.2165 - accuracy: 0.9319 - val_loss: 0.4473 - val_accuracy: 0.8920\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06165\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.2014 - accuracy: 0.9415 - val_loss: 0.0648 - val_accuracy: 0.8400\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06165\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "model1 = get_model()\n",
    "opt=keras.optimizers.SGD(learning_rate=0.01, momentum=0.1, nesterov=True)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model1.fit_generator(training,steps_per_epoch=100,epochs=20,validation_data=test,validation_steps=50,\n",
    "                     callbacks=my_callbacks,verbose=1)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCheck=ModelCheckpoint(filepath=r\"D:/amazon_classifier/amazon_cnn_ADAM.h5\", monitor='val_loss',mode='min',\n",
    "                           save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 149s 1s/step - loss: 2.0107 - accuracy: 0.3258 - val_loss: 1.0900 - val_accuracy: 0.3400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.08996, saving model to D:/amazon_classifier/amazon_cnn_ADAM.h5\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 146s 1s/step - loss: 1.1000 - accuracy: 0.3133 - val_loss: 1.0975 - val_accuracy: 0.3320\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.08996\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 147s 1s/step - loss: 1.0996 - accuracy: 0.3245 - val_loss: 1.0958 - val_accuracy: 0.3320\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.08996\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 146s 1s/step - loss: 1.0998 - accuracy: 0.3133 - val_loss: 1.0974 - val_accuracy: 0.3320\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.08996\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = get_model()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model2.fit_generator(training,steps_per_epoch=100,epochs=20,validation_data=test,validation_steps=50,\n",
    "                     callbacks=my_callbacks,verbose=1)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSPROP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCheck=ModelCheckpoint(filepath=r\"D:/amazon_classifier/amazon_cnn_RMSPROP.h5\", monitor='val_loss',mode='min',\n",
    "                           save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 145s 1s/step - loss: 23.3532 - accuracy: 0.4880 - val_loss: 0.8816 - val_accuracy: 0.6880\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.88155, saving model to D:/amazon_classifier/amazon_cnn_RMSPROP.h5\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 142s 1s/step - loss: 3.1477 - accuracy: 0.6244 - val_loss: 0.7349 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.88155 to 0.73489, saving model to D:/amazon_classifier/amazon_cnn_RMSPROP.h5\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 142s 1s/step - loss: 1.4589 - accuracy: 0.8053 - val_loss: 0.6509 - val_accuracy: 0.7480\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73489 to 0.65088, saving model to D:/amazon_classifier/amazon_cnn_RMSPROP.h5\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 144s 1s/step - loss: 0.8629 - accuracy: 0.9109 - val_loss: 6.8369 - val_accuracy: 0.3320\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.65088\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 143s 1s/step - loss: 1.0855 - accuracy: 0.9269 - val_loss: 4.5461 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.65088\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 142s 1s/step - loss: 1.6769 - accuracy: 0.9469 - val_loss: 10.8976 - val_accuracy: 0.7320\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.65088\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "model3 = get_model()\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model3.fit_generator(training,steps_per_epoch=100,epochs=20,validation_data=test,validation_steps=50,\n",
    "                     callbacks=my_callbacks,verbose=1)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCheck=ModelCheckpoint(filepath=r\"D:/amazon_classifier/amazon_cnn_NADAM.h5\", monitor='val_loss',mode='min',\n",
    "                           save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 147s 1s/step - loss: 1.8104 - accuracy: 0.5796 - val_loss: 0.7030 - val_accuracy: 0.7360\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70304, saving model to D:/amazon_classifier/amazon_cnn_NADAM.h5\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 147s 1s/step - loss: 2.5423 - accuracy: 0.7753 - val_loss: 18.1393 - val_accuracy: 0.3320\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.70304\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 151s 2s/step - loss: 1.0918 - accuracy: 0.6256 - val_loss: 0.4291 - val_accuracy: 0.6920\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70304 to 0.42908, saving model to D:/amazon_classifier/amazon_cnn_NADAM.h5\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.7965 - accuracy: 0.6335 - val_loss: 1.8393 - val_accuracy: 0.4800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42908\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 152s 2s/step - loss: 0.5829 - accuracy: 0.7573 - val_loss: 5.2884 - val_accuracy: 0.4840\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42908\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.3727 - accuracy: 0.8428 - val_loss: 0.2826 - val_accuracy: 0.6120\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42908 to 0.28256, saving model to D:/amazon_classifier/amazon_cnn_NADAM.h5\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 158s 2s/step - loss: 0.3303 - accuracy: 0.8803 - val_loss: 2.1431 - val_accuracy: 0.5400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28256\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.1564 - accuracy: 0.9480 - val_loss: 2.3808 - val_accuracy: 0.5880\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28256\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.1394 - accuracy: 0.9559 - val_loss: 4.7512 - val_accuracy: 0.5760\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28256\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 00009: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 3,697,059\n",
      "Trainable params: 3,697,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model4 = get_model()\n",
    "opt = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model4.fit_generator(training,steps_per_epoch=100,epochs=20,validation_data=test,validation_steps=50,\n",
    "                     callbacks=my_callbacks,verbose=1)\n",
    "K.clear_session()\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see the differnt optimizers and callbacks techniques in action in this assigment , we can alter the callbacks values** \n",
    "**for desired level of results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
